{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpecDDB_GGLl"
      },
      "source": [
        "# WebSem Project: Constructing and Querying a Knowledge Graph in the Cycling Domain\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The goal of this project is to extract information from multilingual textual documents about cycling and create a knowledge graph (KG) using the extracted entities and relations. The KG will be compatible with a cycling ontology and queries will be written in SPARQL to retrieve specific information from the KG. The project will be implemented using Jupyter Notebook and the following steps will be followed:\n",
        "\n",
        "* Collect multilingual textual documents about cycling.\n",
        "* Pre-process the documents to get clean text files.\n",
        "* Run named entity recognition (NER) on the documents to extract named entities of the type Person, Organization and Location using spaCy and LLMs.\n",
        "* Run co-reference resolution on the input text using spaCy.\n",
        "* Disambiguate the entities with Wikidata using OpenTapioca and LLMs.\n",
        "* Run relation extraction using Stanford OpenIE and LLMs.\n",
        "* Implement some mappings between the entity types and relations returned with the cycling ontology you developed during the Assignment 1 in order to create a knowledge graph of the domain represented in RDF.\n",
        "* Load the data in the Corese engine as you did for the Assignment 2 with your cycling ontology and the knowledge graph built in the previous step and write some SPARQL queries to retrieve specific information from the KG.\n",
        "\n",
        "### Useful resources\n",
        "* The github repository \"Building knowledge graph from input data\" at  https://github.com/varun196/knowledge_graph_from_unstructured_text can be used as an inspiration.\n",
        "\n",
        "### References\n",
        "* NLTK: https://www.nltk.org/\n",
        "* spaCy: https://spacy.io/\n",
        "* Stanford OpenIE: https://nlp.stanford.edu/software/openie.html\n",
        "* OpenTapioca: https://opentapioca.org/\n",
        "* Corese engine: https://project.inria.fr/corese/\n",
        "* Wikidata: https://www.wikidata.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzMinLFxGUFx"
      },
      "source": [
        "## Step 1: Collect multilingual textual documents about cycling\n",
        "For this mini project, we will collect multilingual textual documents about cycling from various sources such as news articles, blog posts, and race reports. We will download the documents and save them in a directory called `cycling_docs`.\n",
        "\n",
        "The list of documents to download are available at:\n",
        "\n",
        "* English:\n",
        " - https://en.wikipedia.org/wiki/2022_Tour_de_France\n",
        " - https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_1_to_Stage_11\n",
        " - https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_12_to_Stage_21\n",
        " - https://www.bbc.com/sport/cycling/61940037\n",
        " - https://www.bbc.com/sport/cycling/62017114 (stage 1)\n",
        " - https://www.bbc.com/sport/cycling/62097721 (stage 7)\n",
        " - https://www.bbc.com/sport/cycling/62153759 (stage 11)\n",
        " - https://www.bbc.co.uk/sport/cycling/62285420 (stage 21)\n",
        "\n",
        "* French:\n",
        " - https://fr.wikipedia.org/wiki/Tour_de_France_2022\n",
        " - https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-epoustouflant-jonas-vingegaard-remporte-la-11e-etape-et-s-empare-du-maillot-jaune-de-tadej-pogacar_5254102.html\n",
        " - https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-jonas-vingegaard-vainqueur-de-sa-premiere-grande-boucle-jasper-philipsen-s-offre-au-sprint-la-21e-etape_5275612.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HccrPk8uGVz3"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Feel free to install more dependencies if needed!\n",
        "#\n",
        "\n",
        "# Install requests for querying HTTP endpoints\n",
        "!pip install --quiet requests\n",
        "\n",
        "# Install jusText for automatically extracting text from web pages\n",
        "!pip install --quiet jusText\n",
        "\n",
        "# Install nltk for text processing\n",
        "!pip install --quiet nltk\n",
        "\n",
        "# Install spaCy for NER extraction\n",
        "!pip install --quiet spacy\n",
        "\n",
        "# Install pycorenlp for Stanford CoreNLP\n",
        "!pip install --quiet pycorenlp\n",
        "\n",
        "# Install pandas for data visualization\n",
        "!pip install --quiet pandas\n",
        "\n",
        "# Install rdflib for writing RDF\n",
        "!pip install --quiet rdflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_031XjozIHqs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mymac/Study Abroad/Master Computer Science EURECOM/WebSem/Meeting Day 6/Task/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded https://en.wikipedia.org/wiki/2022_Tour_de_France into cycling_docs/english/2022_Tour_de_France.txt\n",
            "Downloaded https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_1_to_Stage_11 into cycling_docs/english/2022_Tour_de_France,_Stage_1_to_Stage_11.txt\n",
            "Downloaded https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_12_to_Stage_21 into cycling_docs/english/2022_Tour_de_France,_Stage_12_to_Stage_21.txt\n",
            "Downloaded https://www.bbc.com/sport/cycling/61940037 into cycling_docs/english/61940037.txt\n",
            "Downloaded https://www.bbc.com/sport/cycling/62017114 into cycling_docs/english/62017114.txt\n",
            "Downloaded https://www.bbc.com/sport/cycling/62097721 into cycling_docs/english/62097721.txt\n",
            "Downloaded https://www.bbc.com/sport/cycling/62153759 into cycling_docs/english/62153759.txt\n",
            "Downloaded https://www.bbc.co.uk/sport/cycling/62285420 into cycling_docs/english/62285420.txt\n",
            "Downloaded https://fr.wikipedia.org/wiki/Tour_de_France_2022 into cycling_docs/french/Tour_de_France_2022.txt\n",
            "Downloaded https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-epoustouflant-jonas-vingegaard-remporte-la-11e-etape-et-s-empare-du-maillot-jaune-de-tadej-pogacar_5254102.html into cycling_docs/french/tour-de-france-2022-epoustouflant-jonas-vingegaard-remporte-la-11e-etape-et-s-empare-du-maillot-jaune-de-tadej-pogacar_5254102.html.txt\n",
            "Downloaded https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-jonas-vingegaard-vainqueur-de-sa-premiere-grande-boucle-jasper-philipsen-s-offre-au-sprint-la-21e-etape_5275612.html into cycling_docs/french/tour-de-france-2022-jonas-vingegaard-vainqueur-de-sa-premiere-grande-boucle-jasper-philipsen-s-offre-au-sprint-la-21e-etape_5275612.html.txt\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "import requests\n",
        "import justext\n",
        "import os\n",
        "from urllib.parse import urlsplit\n",
        "\n",
        "\n",
        "# Define a function to get filename from URL\n",
        "def get_filename_from_url(url):\n",
        "  urlpath = urlsplit(url).path\n",
        "  return os.path.basename(urlpath)\n",
        "\n",
        "\n",
        "# Define a function to download URLs and extract text\n",
        "def download_urls(urls_list, language):\n",
        "  # Loop over each URL in the list\n",
        "  for url in urls_list:\n",
        "    # Fetch and extract text from the URL using jusText\n",
        "    response = requests.get(url)\n",
        "    paragraphs = justext.justext(\n",
        "      response.content,\n",
        "      justext.get_stoplist(language.capitalize()),\n",
        "      no_headings=True,\n",
        "      max_heading_distance=150,\n",
        "      length_low=70,\n",
        "      length_high=140,\n",
        "      stopwords_low=0.2,\n",
        "      stopwords_high=0.3,\n",
        "      max_link_density=0.4\n",
        "    )\n",
        "    extracted_text = '\\n'.join(list(filter(None, map(\n",
        "      lambda paragraph: paragraph.text if not paragraph.is_boilerplate else '',\n",
        "      paragraphs\n",
        "    ))))\n",
        "\n",
        "    # Truncate text if it's too long\n",
        "    extracted_text = extracted_text[0:10000]\n",
        "\n",
        "    # Create the output directory if it does not exist\n",
        "    output_dir = os.path.join('cycling_docs', language)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save extracted text as a .txt file\n",
        "    filename = get_filename_from_url(url)\n",
        "    output_path = os.path.join(output_dir, f'{filename}.txt')\n",
        "    with open(output_path, 'w') as f:\n",
        "      f.write(extracted_text)\n",
        "\n",
        "    print(f'Downloaded {url} into {output_path}')\n",
        "\n",
        "\n",
        "# List of URLs to download\n",
        "urls_list_english = [\n",
        "  'https://en.wikipedia.org/wiki/2022_Tour_de_France',\n",
        "  'https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_1_to_Stage_11',\n",
        "  'https://en.wikipedia.org/wiki/2022_Tour_de_France,_Stage_12_to_Stage_21',\n",
        "  'https://www.bbc.com/sport/cycling/61940037',\n",
        "  'https://www.bbc.com/sport/cycling/62017114',\n",
        "  'https://www.bbc.com/sport/cycling/62097721',\n",
        "  'https://www.bbc.com/sport/cycling/62153759',\n",
        "  'https://www.bbc.co.uk/sport/cycling/62285420',\n",
        "]\n",
        "urls_list_french = [\n",
        "  'https://fr.wikipedia.org/wiki/Tour_de_France_2022',\n",
        "  'https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-epoustouflant-jonas-vingegaard-remporte-la-11e-etape-et-s-empare-du-maillot-jaune-de-tadej-pogacar_5254102.html',\n",
        "  'https://www.francetvinfo.fr/tour-de-france/tour-de-france-2022-jonas-vingegaard-vainqueur-de-sa-premiere-grande-boucle-jasper-philipsen-s-offre-au-sprint-la-21e-etape_5275612.html',\n",
        "]\n",
        "\n",
        "# Download the listed URLs\n",
        "download_urls(urls_list_english, 'english')\n",
        "download_urls(urls_list_french, 'french')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg52A5ELGWvQ"
      },
      "source": [
        "## Step 2: Pre-process the documents to get clean txt files\n",
        "We will pre-process the documents to get clean txt files by removing any unnecessary characters, punctuation, and stopwords. We will use Python's [re](https://docs.python.org/3/library/re.html) and [nltk](https://www.nltk.org/) libraries for this purpose. We will save the results in a `clean_docs` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t9sdmals1W7w"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Document class which holds all the necessary variables for the purpose of this\n",
        "project.\n",
        "\"\"\"\n",
        "class Document:\n",
        "  def __init__(self, text, language = None, raw_text = None, filepath = None):\n",
        "    self.filepath = filepath    # Path to the document file\n",
        "    self.language = language    # Language of the document\n",
        "    self.raw_text = raw_text    # Origial text before cleaning\n",
        "    self.cleaned_text = text    # Text after cleaning (Step 2)\n",
        "    self.spacy_entities = []    # List of spaCy entities (Step 3a)\n",
        "    self.llm_entities = []      # List of LLM entities (Step 3b)\n",
        "    self.resolved_text = None   # Text after resolving co-references (Step 4)\n",
        "    self.coreferences = None    # CoreNLP coreferences object (Step 4)\n",
        "    self.wiki_entities = {}     # Dictionary of Wikidata entities extracted with OpenTapioca (Step 5a)\n",
        "    self.llm_wiki_entities = {} # Dictionary of Wikidata entities extracted with LLMs (Step 5b)\n",
        "    self.relations = []         # List of OpenIE relations (Step 6a)\n",
        "    self.llm_relations = []     # List of LLM relations (Step 6b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k9JsLAGsxsyI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/mymac/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /Users/mymac/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/mymac/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_text(dirty_text, language):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(dirty_text)\n",
        "    \n",
        "    # Convert to lower case\n",
        "    words = [word.lower() for word in words]\n",
        "    \n",
        "    # Remove punctuation and non-alphabetic characters\n",
        "    words = [re.sub(r'\\W+', '', word) for word in words if word.isalpha()]\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(language))\n",
        "    cleaned_text = ' '.join([word for word in words if word not in stop_words])\n",
        "    \n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KhFqE5TleLz5"
      },
      "outputs": [],
      "source": [
        "# Define a function to process a file and write the result to a new file\n",
        "def process_file(file, language):\n",
        "  # Open the file in read-only mode and read all of its lines\n",
        "  with open(file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "  # Concatenate all the lines into a single string\n",
        "  raw_text = '\\n'.join(lines)\n",
        "\n",
        "  # Clean the text using the `clean_text` function\n",
        "  cleaned_text = clean_text(raw_text, language)\n",
        "\n",
        "  # Create a new document and return it\n",
        "  doc = Document(cleaned_text, language=language, raw_text=raw_text, filepath=os.path.abspath(file))\n",
        "  return doc\n",
        "\n",
        "\n",
        "# Create a list to store all our documents\n",
        "docs = []\n",
        "\n",
        "# Loop through all the files in the \"cycling_docs\" folder\n",
        "folder = 'cycling_docs'\n",
        "for language in os.listdir(folder):\n",
        "  for filename in os.listdir(os.path.join(folder, language)):\n",
        "    # Construct the full path to the file\n",
        "    file = os.path.join(folder, language, filename)\n",
        "\n",
        "    # Check if the file is a regular file and has a .txt extension\n",
        "    if os.path.isfile(file) and file.endswith('.txt'):\n",
        "      # Process the file and append the new Document to our list\n",
        "      doc = process_file(file, language)\n",
        "      docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yi3wcREO1plh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pogacar left pipped vingegaard extend lead danish rider seconds defending champion tadej pogacar beat jonas vingegaard thrilling finish stage seven extended overall lead tour de france pogacar surged past dane last metres claimed second consecutive stage victory lennard kamna looked set win pogacar vingegaard swept final section punishing climb la super planche des belles filles primoz roglic finished third kamna fourth britain geraint thomas tour conceded seconds finished alongside german take heart well positioned throughout concluding climb culminated gradient gravel stretch line ineos grenadiers rider moves third general classification one minute seconds behind pogacar seconds behind vingegaard despair kamna delight pogacar kamna sole survivor breakaway stage tomblaine appeared capable holding famous victory gc race behind ignited final kilometre rider caught final bend pogacar attacked saw vingegaard accelerate past pogacar response fighting back superbly kick line underlined installed favourite win third consecutive edition race really really difficult especially last part jonas vingegaard attacked strong said uae team emirates rider pogacar said yeah boys working day push finish line really special day opened foundation today cancer research wore special shoes today really happy proud take win planche des belle filles britain adam yates remains fourth gc standings tom pidcock dropping seventh overall aleksandr vlasov leader team american neilson powless ef started stage second overall lost significant ground roglic performance two days dislocated shoulder stage five sees climb places overall stage seven results tadej pogacar team emirates jonas vingegaard time primoz roglic secs lennard kamna geraint thomas grenadiers time david gaudu enric mas romain bardet time adam yates grenadiers sepp kuss general classification stage seven tadej pogacar team emirates jonas vingegaard secs geraint thomas grenadiers adam yates grenadiers david gaudu romain bardet tom pidcock grenadiers neilson powless enric mas daniel martinez grenadiers liverpool summit international cocaine trade gangster story curtis warren'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the text of the first document\n",
        "display(docs[0].cleaned_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXH__c_rGaIo"
      },
      "source": [
        "## Step 3: Run named entity recognition (NER) on the documents\n",
        "\n",
        "The goal of this step is to extract named entities from the text of our documents. We will attempt to use two methods: spaCy, and LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsIQKlQoqfL"
      },
      "source": [
        "### Step 3a: Using spaCy\n",
        "\n",
        "We will use [spaCy](https://spacy.io)'s pre-trained models to perform NER on the documents and extract the entities of type PER/ORG/LOC. The extracted entities will be saved in a file.\n",
        "\n",
        "**⚠️ Important Note:** We must use the raw text files (before the cleaning step in Step 2) for NER to ensure we do not lose context or critical information needed for accurate entity recognition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MkMYXqVFGy9t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# 📝 TODO: Import spaCy and other libraries that might be required for entity\n",
        "#          extraction\n",
        "import spacy\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_entities(text, language):\n",
        "  # 📝 TODO: Use spaCy to extract named entities and store them into a list.\n",
        "  # The format of the end result should look like this:\n",
        "  # ```\n",
        "  # entities = [\n",
        "  #   { \"text\": \"Tour de France\", \"label\": \"ORG\" },\n",
        "  #   { \"text\": \"Peter Sagan\", \"label\": \"PERSON\" },\n",
        "  # ]\n",
        "  # ```\n",
        "\n",
        "  # \n",
        "  \n",
        "  doc = nlp(text)\n",
        "\n",
        "  entities = [\n",
        "    { \"text\": ent.text, \"label\": ent.label_ }\n",
        "    for ent in doc.ents\n",
        "    if ent.label_ in ['PERSON', 'ORG', 'GPE']\n",
        "  ]\n",
        "\n",
        "  # Return extracted entities\n",
        "  return entities\n",
        "  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "REq50-k7ePSf"
      },
      "outputs": [],
      "source": [
        "# Extract entities for each document\n",
        "for doc in docs:\n",
        "  doc.spacy_entities = extract_entities(doc.raw_text, doc.language)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkFvU6OfDwux"
      },
      "source": [
        "Display entities which have been extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ER2xsq4WYJgp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Vingegaard', 'label': 'ORG'}, {'text': 'Jonas Vingegaard', 'label': 'PERSON'}, {'text': 'the Tour de France', 'label': 'ORG'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Lennard Kamna', 'label': 'PERSON'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Vingegaard', 'label': 'ORG'}, {'text': 'La Super Planche des Belles Filles', 'label': 'ORG'}, {'text': 'Primoz Roglic', 'label': 'PERSON'}, {'text': 'Kamna', 'label': 'PERSON'}, {'text': 'Britain', 'label': 'GPE'}, {'text': 'Geraint Thomas', 'label': 'PERSON'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': \"Jumbo-Visma's Vingegaard\", 'label': 'ORG'}, {'text': 'Kamna', 'label': 'PERSON'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Kamna', 'label': 'PERSON'}, {'text': 'GC', 'label': 'GPE'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Vingegaard', 'label': 'ORG'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Jonas [Vingegaard', 'label': 'ORG'}, {'text': 'UAE Team Emirates', 'label': 'ORG'}, {'text': 'Pogacar', 'label': 'PERSON'}, {'text': 'Planche des Belle Filles', 'label': 'ORG'}, {'text': 'Britain', 'label': 'GPE'}, {'text': 'Adam Yates', 'label': 'GPE'}, {'text': 'GC', 'label': 'ORG'}, {'text': 'Tom Pidcock', 'label': 'PERSON'}, {'text': 'Aleksandr Vlasov', 'label': 'PERSON'}, {'text': 'the Bora-Hansgrohe', 'label': 'ORG'}, {'text': 'American Neilson Powless', 'label': 'ORG'}, {'text': 'Roglic', 'label': 'PERSON'}, {'text': 'Slo/UAE Team Emirates', 'label': 'ORG'}, {'text': 'Jonas Vingegaard', 'label': 'PERSON'}, {'text': 'Den/Jumbo-Visma', 'label': 'ORG'}, {'text': 'Primoz Roglic', 'label': 'PERSON'}, {'text': 'Lennard Kamna', 'label': 'PERSON'}, {'text': 'Ger/Bora-Hansgrohe', 'label': 'ORG'}, {'text': 'Geraint Thomas', 'label': 'PERSON'}, {'text': 'David Gaudu', 'label': 'PERSON'}, {'text': 'Enric Mas', 'label': 'PERSON'}, {'text': 'Spa/Movistar', 'label': 'ORG'}, {'text': 'Romain Bardet', 'label': 'PERSON'}, {'text': 'Adam Yates', 'label': 'PERSON'}, {'text': 'Sepp Kuss', 'label': 'PERSON'}, {'text': 'US', 'label': 'GPE'}, {'text': 'Slo/UAE Team Emirates', 'label': 'ORG'}, {'text': 'Jonas Vingegaard', 'label': 'PERSON'}, {'text': 'Den/Jumbo-Visma', 'label': 'ORG'}, {'text': 'Geraint Thomas', 'label': 'PERSON'}, {'text': 'Adam Yates', 'label': 'PERSON'}, {'text': 'David Gaudu', 'label': 'PERSON'}, {'text': 'Romain Bardet', 'label': 'PERSON'}, {'text': 'Tom Pidcock', 'label': 'PERSON'}, {'text': 'GB/Ineos Grenadiers', 'label': 'ORG'}, {'text': 'Neilson Powless', 'label': 'ORG'}, {'text': 'US', 'label': 'GPE'}, {'text': 'Enric Mas', 'label': 'PERSON'}, {'text': 'Spa/Movistar', 'label': 'ORG'}, {'text': 'Daniel Martinez', 'label': 'PERSON'}, {'text': 'Col/Ineos Grenadiers', 'label': 'ORG'}, {'text': 'Liverpool', 'label': 'GPE'}]\n"
          ]
        }
      ],
      "source": [
        "# 📝 TODO: Display the extracted entities for the first document\n",
        "print(docs[0].spacy_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7kzYQXsB4E"
      },
      "source": [
        "### Step 3b: Using LLMs\n",
        "\n",
        "**⚠️ Important Note:** We must use the raw text files (before the cleaning step in Step 2) for NER to ensure we do not lose context or critical information needed for accurate entity recognition.\n",
        "\n",
        "First we create a function `llm_generate` which calls an [Ollama](https://ollama.com/) server hosted at EURECOM. For the purpose of this exercise, you are limited to using a specific model (`mistral-nemo:12b-instruct-2407-fp16`). The full documentation for the API is available at: https://github.com/ollama/ollama/blob/main/docs/api.md#generate-a-completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KqUP7q2dnkfG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "# Define a function to call the Ollama WebSem endpoint using a given payload and return the response.\n",
        "def llm_generate(payload):\n",
        "  # Define the API endpoint and payload\n",
        "  url = \"https://websem:eurecom@ollama-websem.tools.eurecom.fr/api/generate\"\n",
        "  payload[\"model\"] = \"mistral-nemo:12b-instruct-2407-fp16\"\n",
        "  payload[\"stream\"] = \"false\"\n",
        "\n",
        "  # Define the headers\n",
        "  headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "  }\n",
        "\n",
        "  # Send the POST request\n",
        "  response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    # Parse the JSON response\n",
        "    response_data = response.json()\n",
        "\n",
        "    # Return the structured entities\n",
        "    return response_data\n",
        "  else:\n",
        "    # Handle errors\n",
        "    print(f\"Error {response.status_code}: {response.text}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL8AiQp8atUZ"
      },
      "source": [
        "Now let's learn how to use it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "FDaZj-VzYZPd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intricate web weaves,\n",
            "Data threads interlocked,\n",
            "Knowledge blooms revealed.\n"
          ]
        }
      ],
      "source": [
        "# Example with basic prompt\n",
        "payload = {\n",
        "  \"prompt\": \"\"\"\n",
        "  Compose a haiku about web semantics, emphasizing the interconnectedness of\n",
        "  data, the elegance of structured knowledge, and the power of understanding\n",
        "  through linked information.\n",
        "  \"\"\"\n",
        "}\n",
        "llm_response = llm_generate(payload)\n",
        "print(llm_response[\"response\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtOr2BtFaUGn"
      },
      "source": [
        "You can even use structured outputs. More informations are available at:\n",
        "* https://ollama.com/blog/structured-outputs\n",
        "* https://github.com/ollama/ollama/blob/main/docs/api.md#request-structured-outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "vJOMGlrsZZdw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"solution\": 4,\n",
            "\"explanation\": \"To solve this problem, we simply add the two numbers together:\\n\\n2 + 2 = 4\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Example with structured outputs\n",
        "payload = {\n",
        "    \"prompt\": \"\"\"\n",
        "    Solve the following math problem and explain the steps clearly:\n",
        "\n",
        "    Problem:\n",
        "    What is 2 + 2?\n",
        "\n",
        "    Provide the solution and explanation in the following structure:\n",
        "    \"\"\",\n",
        "    \"format\": {\n",
        "        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"solution\": {\"type\": \"integer\"},\n",
        "            \"explanation\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"solution\", \"explanation\"]\n",
        "    }\n",
        "}\n",
        "llm_response = llm_generate(payload)\n",
        "print(llm_response[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_entities_with_llm(text):\n",
        "    # Define the custom prompt for extracting named entities\n",
        "    prompt = f\"\"\"\n",
        "    Extract named entities from the following text and format them as a JSON array.\n",
        "    Each entity should be an object with \"text\" and \"label\" fields.\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the payload with the custom prompt and JSON schema for structured output\n",
        "    payload = {\n",
        "        \"prompt\": prompt,\n",
        "        \"format\": {\n",
        "                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                                \"text\": {\"type\": \"string\"},\n",
        "                                \"label\": {\"type\": \"string\"}\n",
        "                        },\n",
        "                        \"required\": [\"text\", \"label\"]\n",
        "                }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Generate the entities using the LLM\n",
        "    llm_output = llm_generate(payload)\n",
        "\n",
        "    # Parse the LLM output to extract entities\n",
        "    try:\n",
        "        entities = json.loads(llm_output[\"response\"])\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle the case where the LLM output is not valid JSON\n",
        "        entities = []\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHoqXoEbb5y"
      },
      "source": [
        "Now let's create a function which can extract entities using `llm_generate` with a custom prompt. There are many ways to achieve this. For example, you could try providing examples, and/or using a JSON schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "45flIC88sPAu"
      },
      "outputs": [],
      "source": [
        "def extract_entities_with_llm(text):\n",
        "  # 📝 TODO: Use LLM to extract named entities and store them into a list.\n",
        "  # The format of the end result should look like this:\n",
        "  # ```\n",
        "  # entities = [\n",
        "  #   { \"text\": \"Tour de France\", \"label\": \"ORG\" },\n",
        "  #   { \"text\": \"Peter Sagan\", \"label\": \"PERSON\" },\n",
        "  # ]\n",
        "  # ```\n",
        "\n",
        "  # 📝\n",
        "    # Define the custom prompt\n",
        "    prompt = f\"\"\"\n",
        "    Extract named entities from the following text and format them as a JSON array.\n",
        "    Each entity should be an object with \"text\" and \"label\" fields.\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the entities using the LLM\n",
        "    llm_output = llm_generate(prompt)\n",
        "\n",
        "    # Parse the LLM output to extract entities\n",
        "    try:\n",
        "        entities = json.loads(llm_output)\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle the case where the LLM output is not valid JSON\n",
        "        entities = []\n",
        "\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8s5r5lXMsc6E"
      },
      "outputs": [],
      "source": [
        "# Extract entities for each document\n",
        "for doc in docs:\n",
        "  doc.llm_entities = extract_entities_with_llm(doc.raw_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRoGApD6tFWx"
      },
      "source": [
        "Display entities which have been extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0-xmKN4dtFWy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': 'Tadej Pogacar', 'label': 'PERSON'},\n",
              " {'text': 'Jonas Vingegaard', 'label': 'PERSON'},\n",
              " {'text': 'Primoz Roglic', 'label': 'PERSON'},\n",
              " {'text': 'Lennard Kamna', 'label': 'PERSON'},\n",
              " {'text': 'Geraint Thomas', 'label': 'PERSON'},\n",
              " {'text': 'Adam Yates', 'label': 'PERSON'},\n",
              " {'text': 'Tom Pidcock', 'label': 'PERSON'},\n",
              " {'text': 'Aleksandr Vlasov', 'label': 'PERSON'},\n",
              " {'text': 'Neilson Powless', 'label': 'PERSON'}]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display entities for the first document\n",
        "display(docs[0].llm_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAsxblm4GceJ"
      },
      "source": [
        "## Step 4: Run co-reference resolution on the input text\n",
        "We will use CoreNLP to perform [co-reference resolution](https://en.wikipedia.org/wiki/Coreference) on the input text and resolve coreferences.\n",
        "\n",
        "For this project, we will use a hosted version of CoreNLP at: https://corenlp.tools.eurecom.fr/ (username: `websem`, password: `eurecom`). Feel free to try out the web interface before writing the code.\n",
        "\n",
        "First, we compute the annotations and store them into the `coreferences` variable of our Document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "v0WOTNW3Ggg5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pycorenlp import StanfordCoreNLP\n",
        "\n",
        "\n",
        "# Set up the CoreNLP client\n",
        "nlp = StanfordCoreNLP('https://websem:eurecom@corenlp.tools.eurecom.fr')\n",
        "\n",
        "# Define a function which computes coreferences for a given text and language\n",
        "def compute_coreferences(text, language):\n",
        "  props = {\n",
        "    'timeout': 300000,\n",
        "    'annotators': 'tokenize,ssplit,coref',\n",
        "    'pipelineLanguage': language[:2],\n",
        "    'outputFormat': 'json'\n",
        "  }\n",
        "\n",
        "  # Annotate the text for co-reference resolution\n",
        "  corenlp_output = nlp.annotate(text, properties=props)\n",
        "  try:\n",
        "    corenlp_output = json.loads(corenlp_output)\n",
        "  except Exception as err:\n",
        "    print(f'Unexpected response: {corenlp_output}')\n",
        "    raise\n",
        "\n",
        "  return corenlp_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ajQ2T6QyhWop"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"sentences\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"basicDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \"engineer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"John\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"compound\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"software\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 6,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \"engineer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"John\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"compound\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"software\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 6,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedPlusPlusDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \"engineer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"John\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"compound\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"software\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 5,\n",
            "          \"governorGloss\": \"engineer\",\n",
            "          \"dependent\": 6,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"entitymentions\": [\n",
            "        {\n",
            "          \"docTokenBegin\": 0,\n",
            "          \"docTokenEnd\": 1,\n",
            "          \"tokenBegin\": 0,\n",
            "          \"tokenEnd\": 1,\n",
            "          \"text\": \"John\",\n",
            "          \"characterOffsetBegin\": 0,\n",
            "          \"characterOffsetEnd\": 4,\n",
            "          \"ner\": \"PERSON\"\n",
            "        },\n",
            "        {\n",
            "          \"docTokenBegin\": 3,\n",
            "          \"docTokenEnd\": 5,\n",
            "          \"tokenBegin\": 3,\n",
            "          \"tokenEnd\": 5,\n",
            "          \"text\": \"software engineer\",\n",
            "          \"characterOffsetBegin\": 10,\n",
            "          \"characterOffsetEnd\": 27,\n",
            "          \"ner\": \"TITLE\"\n",
            "        }\n",
            "      ],\n",
            "      \"tokens\": [\n",
            "        {\n",
            "          \"index\": 1,\n",
            "          \"word\": \"John\",\n",
            "          \"originalText\": \"John\",\n",
            "          \"lemma\": \"John\",\n",
            "          \"characterOffsetBegin\": 0,\n",
            "          \"characterOffsetEnd\": 4,\n",
            "          \"pos\": \"NNP\",\n",
            "          \"ner\": \"PERSON\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \"\",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 2,\n",
            "          \"word\": \"is\",\n",
            "          \"originalText\": \"is\",\n",
            "          \"lemma\": \"be\",\n",
            "          \"characterOffsetBegin\": 5,\n",
            "          \"characterOffsetEnd\": 7,\n",
            "          \"pos\": \"VBZ\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 3,\n",
            "          \"word\": \"a\",\n",
            "          \"originalText\": \"a\",\n",
            "          \"lemma\": \"a\",\n",
            "          \"characterOffsetBegin\": 8,\n",
            "          \"characterOffsetEnd\": 9,\n",
            "          \"pos\": \"DT\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 4,\n",
            "          \"word\": \"software\",\n",
            "          \"originalText\": \"software\",\n",
            "          \"lemma\": \"software\",\n",
            "          \"characterOffsetBegin\": 10,\n",
            "          \"characterOffsetEnd\": 18,\n",
            "          \"pos\": \"NN\",\n",
            "          \"ner\": \"TITLE\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 5,\n",
            "          \"word\": \"engineer\",\n",
            "          \"originalText\": \"engineer\",\n",
            "          \"lemma\": \"engineer\",\n",
            "          \"characterOffsetBegin\": 19,\n",
            "          \"characterOffsetEnd\": 27,\n",
            "          \"pos\": \"NN\",\n",
            "          \"ner\": \"TITLE\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \"\"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 6,\n",
            "          \"word\": \".\",\n",
            "          \"originalText\": \".\",\n",
            "          \"lemma\": \".\",\n",
            "          \"characterOffsetBegin\": 27,\n",
            "          \"characterOffsetEnd\": 28,\n",
            "          \"pos\": \".\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \"\",\n",
            "          \"after\": \" \"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"index\": 1,\n",
            "      \"basicDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"talented\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"He\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"advmod\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"very\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"talented\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"He\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"advmod\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"very\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedPlusPlusDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"talented\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"He\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"advmod\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"very\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"talented\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"entitymentions\": [\n",
            "        {\n",
            "          \"docTokenBegin\": 6,\n",
            "          \"docTokenEnd\": 7,\n",
            "          \"tokenBegin\": 0,\n",
            "          \"tokenEnd\": 1,\n",
            "          \"text\": \"He\",\n",
            "          \"characterOffsetBegin\": 29,\n",
            "          \"characterOffsetEnd\": 31,\n",
            "          \"ner\": \"PERSON\"\n",
            "        }\n",
            "      ],\n",
            "      \"tokens\": [\n",
            "        {\n",
            "          \"index\": 1,\n",
            "          \"word\": \"He\",\n",
            "          \"originalText\": \"He\",\n",
            "          \"lemma\": \"he\",\n",
            "          \"characterOffsetBegin\": 29,\n",
            "          \"characterOffsetEnd\": 31,\n",
            "          \"pos\": \"PRP\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 2,\n",
            "          \"word\": \"is\",\n",
            "          \"originalText\": \"is\",\n",
            "          \"lemma\": \"be\",\n",
            "          \"characterOffsetBegin\": 32,\n",
            "          \"characterOffsetEnd\": 34,\n",
            "          \"pos\": \"VBZ\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 3,\n",
            "          \"word\": \"very\",\n",
            "          \"originalText\": \"very\",\n",
            "          \"lemma\": \"very\",\n",
            "          \"characterOffsetBegin\": 35,\n",
            "          \"characterOffsetEnd\": 39,\n",
            "          \"pos\": \"RB\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 4,\n",
            "          \"word\": \"talented\",\n",
            "          \"originalText\": \"talented\",\n",
            "          \"lemma\": \"talented\",\n",
            "          \"characterOffsetBegin\": 40,\n",
            "          \"characterOffsetEnd\": 48,\n",
            "          \"pos\": \"JJ\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \"\"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 5,\n",
            "          \"word\": \".\",\n",
            "          \"originalText\": \".\",\n",
            "          \"lemma\": \".\",\n",
            "          \"characterOffsetBegin\": 48,\n",
            "          \"characterOffsetEnd\": 49,\n",
            "          \"pos\": \".\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \"\",\n",
            "          \"after\": \" \"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"index\": 2,\n",
            "      \"basicDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"designer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"Sarah\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"designer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"Sarah\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedPlusPlusDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"designer\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"Sarah\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"cop\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"is\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"det\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"a\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"designer\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"entitymentions\": [\n",
            "        {\n",
            "          \"docTokenBegin\": 11,\n",
            "          \"docTokenEnd\": 12,\n",
            "          \"tokenBegin\": 0,\n",
            "          \"tokenEnd\": 1,\n",
            "          \"text\": \"Sarah\",\n",
            "          \"characterOffsetBegin\": 50,\n",
            "          \"characterOffsetEnd\": 55,\n",
            "          \"ner\": \"PERSON\"\n",
            "        },\n",
            "        {\n",
            "          \"docTokenBegin\": 14,\n",
            "          \"docTokenEnd\": 15,\n",
            "          \"tokenBegin\": 3,\n",
            "          \"tokenEnd\": 4,\n",
            "          \"text\": \"designer\",\n",
            "          \"characterOffsetBegin\": 61,\n",
            "          \"characterOffsetEnd\": 69,\n",
            "          \"ner\": \"TITLE\"\n",
            "        }\n",
            "      ],\n",
            "      \"tokens\": [\n",
            "        {\n",
            "          \"index\": 1,\n",
            "          \"word\": \"Sarah\",\n",
            "          \"originalText\": \"Sarah\",\n",
            "          \"lemma\": \"Sarah\",\n",
            "          \"characterOffsetBegin\": 50,\n",
            "          \"characterOffsetEnd\": 55,\n",
            "          \"pos\": \"NNP\",\n",
            "          \"ner\": \"PERSON\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 2,\n",
            "          \"word\": \"is\",\n",
            "          \"originalText\": \"is\",\n",
            "          \"lemma\": \"be\",\n",
            "          \"characterOffsetBegin\": 56,\n",
            "          \"characterOffsetEnd\": 58,\n",
            "          \"pos\": \"VBZ\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 3,\n",
            "          \"word\": \"a\",\n",
            "          \"originalText\": \"a\",\n",
            "          \"lemma\": \"a\",\n",
            "          \"characterOffsetBegin\": 59,\n",
            "          \"characterOffsetEnd\": 60,\n",
            "          \"pos\": \"DT\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 4,\n",
            "          \"word\": \"designer\",\n",
            "          \"originalText\": \"designer\",\n",
            "          \"lemma\": \"designer\",\n",
            "          \"characterOffsetBegin\": 61,\n",
            "          \"characterOffsetEnd\": 69,\n",
            "          \"pos\": \"NN\",\n",
            "          \"ner\": \"TITLE\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \"\"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 5,\n",
            "          \"word\": \".\",\n",
            "          \"originalText\": \".\",\n",
            "          \"lemma\": \".\",\n",
            "          \"characterOffsetBegin\": 69,\n",
            "          \"characterOffsetEnd\": 70,\n",
            "          \"pos\": \".\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \"\",\n",
            "          \"after\": \" \"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"index\": 3,\n",
            "      \"basicDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"works\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"She\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"case\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"him\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"with\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nmod\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"him\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"works\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"She\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"case\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"him\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"with\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nmod:with\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"him\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"enhancedPlusPlusDependencies\": [\n",
            "        {\n",
            "          \"dep\": \"ROOT\",\n",
            "          \"governor\": 0,\n",
            "          \"governorGloss\": \"ROOT\",\n",
            "          \"dependent\": 2,\n",
            "          \"dependentGloss\": \"works\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nsubj\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 1,\n",
            "          \"dependentGloss\": \"She\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"case\",\n",
            "          \"governor\": 4,\n",
            "          \"governorGloss\": \"him\",\n",
            "          \"dependent\": 3,\n",
            "          \"dependentGloss\": \"with\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"nmod:with\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 4,\n",
            "          \"dependentGloss\": \"him\"\n",
            "        },\n",
            "        {\n",
            "          \"dep\": \"punct\",\n",
            "          \"governor\": 2,\n",
            "          \"governorGloss\": \"works\",\n",
            "          \"dependent\": 5,\n",
            "          \"dependentGloss\": \".\"\n",
            "        }\n",
            "      ],\n",
            "      \"entitymentions\": [\n",
            "        {\n",
            "          \"docTokenBegin\": 16,\n",
            "          \"docTokenEnd\": 17,\n",
            "          \"tokenBegin\": 0,\n",
            "          \"tokenEnd\": 1,\n",
            "          \"text\": \"She\",\n",
            "          \"characterOffsetBegin\": 71,\n",
            "          \"characterOffsetEnd\": 74,\n",
            "          \"ner\": \"PERSON\"\n",
            "        },\n",
            "        {\n",
            "          \"docTokenBegin\": 19,\n",
            "          \"docTokenEnd\": 20,\n",
            "          \"tokenBegin\": 3,\n",
            "          \"tokenEnd\": 4,\n",
            "          \"text\": \"him\",\n",
            "          \"characterOffsetBegin\": 86,\n",
            "          \"characterOffsetEnd\": 89,\n",
            "          \"ner\": \"PERSON\"\n",
            "        }\n",
            "      ],\n",
            "      \"tokens\": [\n",
            "        {\n",
            "          \"index\": 1,\n",
            "          \"word\": \"She\",\n",
            "          \"originalText\": \"She\",\n",
            "          \"lemma\": \"she\",\n",
            "          \"characterOffsetBegin\": 71,\n",
            "          \"characterOffsetEnd\": 74,\n",
            "          \"pos\": \"PRP\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 2,\n",
            "          \"word\": \"works\",\n",
            "          \"originalText\": \"works\",\n",
            "          \"lemma\": \"work\",\n",
            "          \"characterOffsetBegin\": 75,\n",
            "          \"characterOffsetEnd\": 80,\n",
            "          \"pos\": \"VBZ\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 3,\n",
            "          \"word\": \"with\",\n",
            "          \"originalText\": \"with\",\n",
            "          \"lemma\": \"with\",\n",
            "          \"characterOffsetBegin\": 81,\n",
            "          \"characterOffsetEnd\": 85,\n",
            "          \"pos\": \"IN\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \" \"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 4,\n",
            "          \"word\": \"him\",\n",
            "          \"originalText\": \"him\",\n",
            "          \"lemma\": \"he\",\n",
            "          \"characterOffsetBegin\": 86,\n",
            "          \"characterOffsetEnd\": 89,\n",
            "          \"pos\": \"PRP\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \" \",\n",
            "          \"after\": \"\"\n",
            "        },\n",
            "        {\n",
            "          \"index\": 5,\n",
            "          \"word\": \".\",\n",
            "          \"originalText\": \".\",\n",
            "          \"lemma\": \".\",\n",
            "          \"characterOffsetBegin\": 89,\n",
            "          \"characterOffsetEnd\": 90,\n",
            "          \"pos\": \".\",\n",
            "          \"ner\": \"O\",\n",
            "          \"speaker\": \"PER0\",\n",
            "          \"before\": \"\",\n",
            "          \"after\": \"\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"corefs\": {\n",
            "    \"5\": [\n",
            "      {\n",
            "        \"id\": 3,\n",
            "        \"text\": \"Sarah\",\n",
            "        \"type\": \"PROPER\",\n",
            "        \"number\": \"SINGULAR\",\n",
            "        \"gender\": \"FEMALE\",\n",
            "        \"animacy\": \"ANIMATE\",\n",
            "        \"startIndex\": 1,\n",
            "        \"endIndex\": 2,\n",
            "        \"headIndex\": 1,\n",
            "        \"sentNum\": 3,\n",
            "        \"position\": [\n",
            "          3,\n",
            "          1\n",
            "        ],\n",
            "        \"isRepresentativeMention\": true\n",
            "      },\n",
            "      {\n",
            "        \"id\": 5,\n",
            "        \"text\": \"She\",\n",
            "        \"type\": \"PRONOMINAL\",\n",
            "        \"number\": \"SINGULAR\",\n",
            "        \"gender\": \"FEMALE\",\n",
            "        \"animacy\": \"ANIMATE\",\n",
            "        \"startIndex\": 1,\n",
            "        \"endIndex\": 2,\n",
            "        \"headIndex\": 1,\n",
            "        \"sentNum\": 4,\n",
            "        \"position\": [\n",
            "          4,\n",
            "          1\n",
            "        ],\n",
            "        \"isRepresentativeMention\": false\n",
            "      }\n",
            "    ],\n",
            "    \"6\": [\n",
            "      {\n",
            "        \"id\": 0,\n",
            "        \"text\": \"John\",\n",
            "        \"type\": \"PROPER\",\n",
            "        \"number\": \"SINGULAR\",\n",
            "        \"gender\": \"MALE\",\n",
            "        \"animacy\": \"ANIMATE\",\n",
            "        \"startIndex\": 1,\n",
            "        \"endIndex\": 2,\n",
            "        \"headIndex\": 1,\n",
            "        \"sentNum\": 1,\n",
            "        \"position\": [\n",
            "          1,\n",
            "          1\n",
            "        ],\n",
            "        \"isRepresentativeMention\": true\n",
            "      },\n",
            "      {\n",
            "        \"id\": 2,\n",
            "        \"text\": \"He\",\n",
            "        \"type\": \"PRONOMINAL\",\n",
            "        \"number\": \"SINGULAR\",\n",
            "        \"gender\": \"MALE\",\n",
            "        \"animacy\": \"ANIMATE\",\n",
            "        \"startIndex\": 1,\n",
            "        \"endIndex\": 2,\n",
            "        \"headIndex\": 1,\n",
            "        \"sentNum\": 2,\n",
            "        \"position\": [\n",
            "          2,\n",
            "          1\n",
            "        ],\n",
            "        \"isRepresentativeMention\": false\n",
            "      },\n",
            "      {\n",
            "        \"id\": 6,\n",
            "        \"text\": \"him\",\n",
            "        \"type\": \"PRONOMINAL\",\n",
            "        \"number\": \"SINGULAR\",\n",
            "        \"gender\": \"MALE\",\n",
            "        \"animacy\": \"ANIMATE\",\n",
            "        \"startIndex\": 4,\n",
            "        \"endIndex\": 5,\n",
            "        \"headIndex\": 4,\n",
            "        \"sentNum\": 4,\n",
            "        \"position\": [\n",
            "          4,\n",
            "          2\n",
            "        ],\n",
            "        \"isRepresentativeMention\": false\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Test co-references computation\n",
        "example = compute_coreferences(\"John is a software engineer. He is very talented. Sarah is a designer. She works with him.\", language=\"en\")\n",
        "\n",
        "# Pretty-print them\n",
        "print(json.dumps(example, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FSnVwbZkhUii"
      },
      "outputs": [],
      "source": [
        "# Compute co-references for all documents\n",
        "for doc in docs:\n",
        "  if doc.language == \"english\":  # CoreNLP Coref-resolution only supports english\n",
        "    doc.coreferences = compute_coreferences(doc.raw_text, doc.language)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBqJ8DTtoFpN"
      },
      "source": [
        "The first step is to display all co-references for each mentions in the text.\n",
        "\n",
        "For example:\n",
        "\n",
        "> \"He\" -> \"John\"\n",
        ">\n",
        "> \"She\" -> \"Sarah\"\n",
        ">\n",
        "> \"him\" -> \"John\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vp2BHxDHoSUd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"She\" -> \"Sarah\"\n",
            "\"He\" -> \"John\"\n",
            "\"him\" -> \"John\"\n"
          ]
        }
      ],
      "source": [
        "for coref_cluster in example['corefs'].values():\n",
        "  # 📝 TODO: Print each co-references like so: \"He\" -> \"John\"\n",
        "  # 💡 Each cluster has one representative mention, flagged with `isRepresentativeMention: True`\n",
        "  for mention in coref_cluster:\n",
        "    if not mention['isRepresentativeMention']:\n",
        "      # Find the representative mention\n",
        "      representative_mention = next(m for m in coref_cluster if m['isRepresentativeMention'])\n",
        "      print(f'\"{mention[\"text\"]}\" -> \"{representative_mention[\"text\"]}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVhTqao-5Z55"
      },
      "source": [
        "### 🏆 Challenge\n",
        "\n",
        "Replace values within the text with their resolved co-reference. For example, with the following text:\n",
        "\n",
        "> **John** is a software engineer. **He** is very talented.\n",
        "\n",
        "In the second sentence, the pronoun \"He\" would be replaced with its co-reference, and the final text would become:\n",
        "\n",
        "> **John** is a software engineer. **John** is very talented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "V4P_mgqCeebD"
      },
      "outputs": [],
      "source": [
        "def resolve_coreferences(corenlp_output):\n",
        "  # 📝 TODO: Replace values within the text with their resolved co-reference.\n",
        "  # 💡 You can start by printing the `corenlp_output` object to understand its\n",
        "  #    structure.\n",
        "  sentences = corenlp_output['sentences']\n",
        "  corefs = corenlp_output['corefs']\n",
        "\n",
        "  # Create a list to hold the resolved sentences\n",
        "  resolved_sentences = []\n",
        "\n",
        "  # Iterate through each sentence\n",
        "  for sentence in sentences:\n",
        "    tokens = sentence['tokens']\n",
        "    resolved_sentence = []\n",
        "\n",
        "    # Iterate through each token in the sentence\n",
        "    for token in tokens:\n",
        "      token_text = token['originalText']\n",
        "      token_index = token['index']\n",
        "\n",
        "      # Check if the token is part of a coreference\n",
        "      for coref_cluster in corefs.values():\n",
        "        for mention in coref_cluster:\n",
        "          if mention['sentNum'] == sentence['index'] + 1 and mention['startIndex'] <= token_index < mention['endIndex']:\n",
        "            if not mention['isRepresentativeMention']:\n",
        "              # Find the representative mention\n",
        "              representative_mention = next(m for m in coref_cluster if m['isRepresentativeMention'])\n",
        "              token_text = representative_mention['text']\n",
        "            break\n",
        "\n",
        "      resolved_sentence.append(token_text)\n",
        "\n",
        "    resolved_sentences.append(' '.join(resolved_sentence))\n",
        "\n",
        "  # Join the resolved sentences to form the final resolved text\n",
        "  resolved_text = ' '.join(resolved_sentences)\n",
        "\n",
        "  return resolved_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5rXXcAtMklMk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "John is a software engineer. He is very talented. Sarah is a designer. She works with him.\n",
            "John is a software engineer . John is very talented . Sarah is a designer . Sarah works with John .\n"
          ]
        }
      ],
      "source": [
        "# Test resolving co-references\n",
        "original_text = \"John is a software engineer. He is very talented. Sarah is a designer. She works with him.\"\n",
        "corefs = compute_coreferences(original_text, language=\"en\")\n",
        "resolved_text = resolve_coreferences(corefs)\n",
        "print(original_text)\n",
        "print(resolved_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ntDsoAUikd4U"
      },
      "outputs": [],
      "source": [
        "# Resolve co-references for all documents\n",
        "for doc in docs:\n",
        "  if doc.coreferences is not None:\n",
        "    doc.resolved_text = resolve_coreferences(doc.coreferences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hINiwG5V-__O"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Denmark \\'s Jonas Vingegaard secured Denmark \\'s Jonas Vingegaard first Tour de France victory as Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard won the sprint on the final stage in Paris . Denmark \\'s Jonas Vingegaard was an easy winner on the Champs-Elysees while Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard , finished alongside Denmark \\'s Jonas Vingegaard Jumbo-Visma team-mates after three weeks of racing . Denmark \\'s Jonas Vingegaard beat last year \\'s champion Tadej Pogacar by two minutes 43 seconds in the general classification . the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up came third overall . The 36-year-old Welshman has now finished on the this year \\'s Tour podium three times in the best team award Welshman Thomas , the 2018 champion and 2019 runner-up career . \" Now nothing can go wrong any more . I \\'m sitting here with I daughter . It \\'s just incredible . \" It is the biggest cycling race of the year , the biggest one you can win and now I have done it . Nobody can take this away from I . \" The runner-up last year \\'s last year \\'s , Denmark \\'s Jonas Vingegaard also claimed the polka dot king of the mountains jersey , while team-mate Wout van Aert won the points classification green jersey . last year \\'s champion Tadej Pogacar last year \\'s champion Tadej Pogacar last year \\'s champion Tadej Pogacar , had to settle for the mountains jersey the mountains jersey the mountains jersey as the best young rider after Denmark \\'s Jonas Vingegaard dream of a third straight this year \\'s Tour title was ended in the mountains . Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard Denmark \\'s Jonas Vingegaard , is Denmark \\'s Denmark \\'s second this year \\'s Tour winner after Bjarne Riis \\' victory in 1996 . Where this year \\'s Tour this year \\'s Tour this year \\'s Tour was won this year \\'s Tour this year \\'s Tour this year \\'s Tour was ultimately decided on stage 11 , as Denmark \\'s Jonas Vingegaard launched a stunning attack on the final Col du Granon climb to take the overall lead from Pogacar . Pogacar had worn the mountains jersey the mountains jersey the mountains jersey for five stages , and led by 39 seconds , but Denmark \\'s Jonas Vingegaard took full advantage of a rare difficult moment for the Slovenian to establish a lead of over two minutes to Denmark \\'s Jonas Vingegaard main rival that day . Pogacar was able to edge Denmark \\'s Jonas Vingegaard to win an epic mountain battle on stage 17 - however his first Tour de France victory as Jasper Philipsen of Belgium his first Tour de France victory as Jasper Philipsen of Belgium his first Tour de France victory as Jasper Philipsen of Belgium his first Tour de France victory as Jasper Philipsen of Belgium his first Tour de France victory as Jasper Philipsen of Belgium was all but confirmed as Denmark \\'s Jonas Vingegaard extended a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day a lead of over two minutes to his main rival that day . the final stage in Paris the final stage in Paris also witnessed a brilliant act of sportsmanship from Vingegaard , who waited for and shook hands with Pogacar after the two-time champion crashed as the pair went head-to-head for the mountains jersey the mountains jersey the mountains jersey . the pair was a demonstration of the huge respect between two young riders who look set to enjoy many more memorable battles at this year \\'s Tour this year \\'s Tour for years to come . \" I always had the feeling that at least I could fight for the win , \" Denmark \\'s Jonas Vingegaard said . \" But I think in the end when I really started believing was after Hautacam . I always believed in the end but I was thinking something really has to go wrong after Hautacam . \" the best team award Welshman Thomas , the 2018 champion and 2019 runner-up keen to \\' soak up \\' third place Image source , Getty Images Image caption , the best team award Welshman Thomas , the 2018 champion and 2019 runner-up the best team award Welshman Thomas , the 2018 champion and 2019 runner-up \\' team Ineos Grenadiers won the best team award Welshman Thomas , the 2018 champion and 2019 runner-up , said he was \" satisfied \" after \" proving a few people wrong \" with he performance at this year \\'s Tour . The 36-year-old was a clear third-best behind what he has described as two \" exceptional talents \" in Denmark \\'s Jonas Vingegaard and Pogacar , but also comfortably ahead of the rest of the field . Not content to enjoy he achievement on the Champs-Elysees the Champs-Elysees , the best team award Welshman Thomas , the 2018 champion and 2019 runner-up attacked inside the final few kilometres of the iconic final stage alongside team-mate Filippo Ganna , before Pogacar then enjoyed a brief spell on the front . Asked about that move , the best team award Welshman Thomas , the 2018 champion and 2019 runner-up told ITV : \" We knew We were always up against ITV but you \\'ve just got to have a go . the best team award Welshman Thomas , the 2018 champion and 2019 runner-up just enjoyed racing . \" On sealing another podium finish , he added : \" he can see he \\'m much closer to the end of his career his career than the start so he \\'m really making the most of his career . \" he just want to soak his career all in and enjoy days like this because they do n\\'t come around too often . \"'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 📝 TODO: Display text with resolved co-references for the any document of your choice\n",
        "docs[4].resolved_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIQZdbp9Gg6v"
      },
      "source": [
        "## Step 5: Disambiguate the entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuIkf6vnrX-y"
      },
      "source": [
        "We will reuse the same method `llm_generate` from Step 3, but with a different prompt in order to disambiguate the entities from Wikidata and DBpedia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "CUkHtwaqTDTQ"
      },
      "outputs": [],
      "source": [
        "def disambiguate_with_llm(text):\n",
        "  # 📝 TODO: Use LLM to disambiguate entities according to Wikidata\n",
        "  # Define the custom prompt for disambiguating entities with Wikidata\n",
        "  prompt_wikidata = f\"\"\"\n",
        "  Disambiguate the following entities according to Wikidata and format them as a JSON array.\n",
        "  Each entity should be an object with \"text\", \"label\", and \"wikidata_id\" fields.\n",
        "  Provide the disambiguated entities in the following format:\n",
        "    [\n",
        "      {{ \"text\": \"Tour de France\", \"wikidata\": \"Q12345\" }},\n",
        "      {{ \"text\": \"Peter Sagan\", \"wikidata\": \"Q67890\" }},\n",
        "    ]\n",
        "  Text: {text}\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Generate the entities using the LLM for Wikidata\n",
        "  llm_output_wikidata = llm_generate({\"prompt\": prompt_wikidata})\n",
        "\n",
        "  # Parse the LLM output to extract Wikidata entities\n",
        "  try:\n",
        "    wikidata_entities = json.loads(llm_output_wikidata[\"response\"])\n",
        "  except json.JSONDecodeError:\n",
        "     # Handle the case where the LLM output is not valid JSON\n",
        "     wikidata_entities = []\n",
        "\n",
        "  # Define the custom prompt for disambiguating entities with DBpedia\n",
        "  prompt_dbpedia = f\"\"\"\n",
        "  Disambiguate the following entities according to DBpedia and format them as a JSON array.\n",
        "  Each entity should be an object with \"text\", \"label\", and \"dbpedia_uri\" fields.\n",
        "  Provide the disambiguated entities in the following format:\n",
        "    [\n",
        "      {{ \"text\": \"Tour de France\",\"dbpedia\": \"Tour_de_France\" }},\n",
        "      {{ \"text\": \"Peter Sagan\", \"dbpedia\": \"Peter_Sagan\" }},\n",
        "    ]\n",
        "  Text: {text}\n",
        "  \"\"\"\n",
        "\n",
        "  \n",
        "  # 📝 TODO: Use LLM to disambiguate entities according to DBpedia\n",
        "  # Generate the entities using the LLM for DBpedia\n",
        "  llm_output_dbpedia = llm_generate({\"prompt\": prompt_dbpedia})\n",
        "\n",
        "  # Parse the LLM output to extract DBpedia entities\n",
        "  try:\n",
        "    dbpedia_entities = json.loads(llm_output_dbpedia[\"response\"])\n",
        "  except json.JSONDecodeError:\n",
        "    # Handle the case where the LLM output is not valid JSON\n",
        "    dbpedia_entities = []\n",
        "\n",
        "  # Combine the disambiguated entities\n",
        "  disambiguated_entities = {\n",
        "    \"wikidata\": wikidata_entities,\n",
        "    \"dbpedia\": dbpedia_entities\n",
        "  }\n",
        "\n",
        "  return disambiguated_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "3v2QQmase3CD"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "  doc.wiki_entities = {}\n",
        "  entities = {}\n",
        "  for j in range(0, len(doc.raw_text), 4000):\n",
        "    doc.wiki_entities |= disambiguate_with_llm(doc.raw_text[j:j+4000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cC1zoDSe5BF"
      },
      "source": [
        "Display the entities disambiguated according to DBpedia and Wikidata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "B80_ZKM7SoIF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'wikidata': [{'text': 'Tour de France', 'wikidata_id': 'Q12345'},\n",
              "  {'text': 'Tadej Pogačar', 'wikidata_id': 'Q67890'},\n",
              "  {'text': 'Jonas Vingegaard', 'wikidata_id': 'Q102345'},\n",
              "  {'text': 'Wout van Aert', 'wikidata_id': 'Q26789'},\n",
              "  {'text': 'Christophe Laporte', 'wikidata_id': 'Q15230213'}],\n",
              " 'dbpedia': [{'text': 'Tour de France',\n",
              "   'dbpedia_uri': 'http://dbpedia.org/resource/Tour_de_France'},\n",
              "  {'text': 'Tadej Pogačar',\n",
              "   'dbpedia_uri': 'http://dbpedia.org/resource/Tadej_Poga%C4%8Dar'},\n",
              "  {'text': 'Jonas Vingegaard',\n",
              "   'dbpedia_uri': 'http://dbpedia.org/resource/Jonas_Vingegaard'},\n",
              "  {'text': 'Wout van Aert',\n",
              "   'dbpedia_uri': 'http://dbpedia.org/resource/Wout_van_Aert'},\n",
              "  {'text': 'Geraint Thomas',\n",
              "   'dbpedia_uri': 'http://dbpedia.org/resource/Geraint_Thomas_(cyclist)'}]}"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 📝 TODO: Display extracted Wikidata entities for the first document\n",
        "docs[1].wiki_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "VJs0r4buN9tH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': 'Tour de France',\n",
              "  'dbpedia_uri': 'http://dbpedia.org/resource/Tour_de_France'},\n",
              " {'text': 'Tadej Pogačar',\n",
              "  'dbpedia_uri': 'http://dbpedia.org/resource/Tadej_Poga%C4%8Dar'},\n",
              " {'text': 'Jonas Vingegaard',\n",
              "  'dbpedia_uri': 'http://dbpedia.org/resource/Jonas_Vingegaard'},\n",
              " {'text': 'Wout van Aert',\n",
              "  'dbpedia_uri': 'http://dbpedia.org/resource/Wout_van_Aert'},\n",
              " {'text': 'Geraint Thomas',\n",
              "  'dbpedia_uri': 'http://dbpedia.org/resource/Geraint_Thomas_(cyclist)'}]"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 📝 TODO: Display extracted DBpedia entities for the first document\n",
        "docs[1].wiki_entities['dbpedia']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvv056SGirj"
      },
      "source": [
        "## Step 6: Run relation extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDLkGwsxrsOL"
      },
      "source": [
        "### Step 6a: Using OpenIE\n",
        "\n",
        "We will use [Stanford OpenIE](https://nlp.stanford.edu/software/openie.html) to extract the relations between the entities in the input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "mVVKYu3CGjaC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pycorenlp import StanfordCoreNLP\n",
        "\n",
        "# Create a StanfordCoreNLP object\n",
        "nlp = StanfordCoreNLP('https://websem:eurecom@corenlp.tools.eurecom.fr')\n",
        "\n",
        "# Define a function to extract relations from input text using Stanford OpenIE\n",
        "def extract_relations_with_openie(input_text, language):\n",
        "  output = nlp.annotate(input_text, properties={\n",
        "    'timeout': 300000,\n",
        "    'annotators': 'tokenize,ssplit,openie',\n",
        "    'outputFormat': 'json',\n",
        "    'pipelineLanguage': language[:2]\n",
        "  })\n",
        "  try:\n",
        "    output = json.loads(output)\n",
        "  except Exception as err:\n",
        "    print(f'Unexpected response: {output}')\n",
        "    raise\n",
        "\n",
        "# 📝 TODO: Get relations from the `output` object (subject, relation, object)\n",
        "#    and append them to a `extracted_relations` list.\n",
        "# 💡 You can start by printing the `output` object to understand its structure.\n",
        "  extracted_relations = []\n",
        "  for sentence in output.get('sentences', []):\n",
        "    for openie in sentence.get('openie', []):\n",
        "      relation = {\n",
        "        'subject': openie.get('subject'),\n",
        "        'relation': openie.get('relation'),\n",
        "        'object': openie.get('object')\n",
        "      }\n",
        "      extracted_relations.append(relation)\n",
        "\n",
        "  # Return relations\n",
        "  return extracted_relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Wa4T96f1f2Yd"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "  if doc.language == \"english\":  # CoreNLP OpenIE only supports english\n",
        "    doc.relations = extract_relations_with_openie(doc.raw_text, doc.language)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSSohZ89_7Xk"
      },
      "source": [
        "Display relations which have been extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "VI5oEP91-l66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'subject': 'Jonas Vingegaard',\n",
              "  'relation': 'took lead',\n",
              "  'object': 'he burst'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'attack on final climb'},\n",
              " {'subject': 'clear', 'relation': 'attack on', 'object': 'final climb'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'attack on',\n",
              "  'object': 'final climb of stage 11'},\n",
              " {'subject': 'Jonas Vingegaard', 'relation': 'took', 'object': 'lead'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'stunning attack on climb of stage 11'},\n",
              " {'subject': 'clear', 'relation': 'launched', 'object': 'attack'},\n",
              " {'subject': 'clear', 'relation': 'launched attack', 'object': 'claim'},\n",
              " {'subject': 'clear', 'relation': 'attack on', 'object': 'climb of stage 11'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'attack on final climb of stage 11'},\n",
              " {'subject': 'clear', 'relation': 'launched', 'object': 'stunning attack'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'stunning attack on final climb'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'stunning attack on climb'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'attack on climb of stage 11'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'stunning attack on',\n",
              "  'object': 'climb of stage 11'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'stunning attack on',\n",
              "  'object': 'final climb'},\n",
              " {'subject': 'clear', 'relation': 'launched', 'object': 'attack on climb'},\n",
              " {'subject': 'clear', 'relation': 'attack on', 'object': 'climb'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'launched',\n",
              "  'object': 'stunning attack on final climb of stage 11'},\n",
              " {'subject': 'clear', 'relation': 'stunning attack on', 'object': 'climb'},\n",
              " {'subject': 'Jonas Vingegaard', 'relation': 'took', 'object': 'big lead'},\n",
              " {'subject': 'clear',\n",
              "  'relation': 'stunning attack on',\n",
              "  'object': 'final climb of stage 11'},\n",
              " {'subject': 'overall contenders', 'relation': 'would go', 'object': 'head'},\n",
              " {'subject': 'contenders', 'relation': 'would go to', 'object': 'head'},\n",
              " {'subject': 'overall contenders',\n",
              "  'relation': 'would go head to',\n",
              "  'object': 'head'},\n",
              " {'subject': 'contenders', 'relation': 'would go head to', 'object': 'head'},\n",
              " {'subject': 'contenders', 'relation': 'would go', 'object': 'head'},\n",
              " {'subject': 'km Alpine stage', 'relation': 'lived as', 'object': 'day'},\n",
              " {'subject': '151.7 km Alpine stage', 'relation': 'lived as', 'object': 'day'},\n",
              " {'subject': '151.7 km Alpine stage',\n",
              "  'relation': 'lived up',\n",
              "  'object': 'up its billing'},\n",
              " {'subject': 'km Alpine stage',\n",
              "  'relation': 'lived up',\n",
              "  'object': 'up its billing'},\n",
              " {'subject': 'overall contenders',\n",
              "  'relation': 'would go to',\n",
              "  'object': 'head'},\n",
              " {'subject': '25-year-old', 'relation': 'for', 'object': 'first Tour stage'},\n",
              " {'subject': 'burst', 'relation': 'win atop', 'object': 'Col du Granon'},\n",
              " {'subject': 'Jumbo-Visma', 'relation': 'has', 'object': 'Vingegaard'},\n",
              " {'subject': 'burst',\n",
              "  'relation': 'clear for',\n",
              "  'object': \"25-year-old 's Tour stage\"},\n",
              " {'subject': 'burst',\n",
              "  'relation': 'clear for',\n",
              "  'object': \"25-year-old 's first Tour stage\"},\n",
              " {'subject': 'burst clear', 'relation': 'win atop', 'object': 'Col du Granon'},\n",
              " {'subject': 'Dane',\n",
              "  'relation': 'leads with',\n",
              "  'object': 'Pogacar narrowly further back'},\n",
              " {'subject': 'Dane',\n",
              "  'relation': 'leads with',\n",
              "  'object': 'Pogacar further back'},\n",
              " {'subject': 'Dane', 'relation': 'leads with', 'object': 'Pogacar'},\n",
              " {'subject': 'Dane',\n",
              "  'relation': 'leads with',\n",
              "  'object': 'Pogacar narrowly back'},\n",
              " {'subject': 'Dane', 'relation': 'leads with', 'object': 'Pogacar back'},\n",
              " {'subject': 'he', 'relation': 'Asked', 'object': 'he could believe'},\n",
              " {'subject': 'it', 'relation': 'is', 'object': 'incredible'},\n",
              " {'subject': 'it', 'relation': 'is', 'object': 'really incredible'},\n",
              " {'subject': 'It', 'relation': 'is', 'object': 'hard'},\n",
              " {'subject': 'me', 'relation': 'put on', 'object': 'words'},\n",
              " {'subject': 'stage', 'relation': 'is in', 'object': 'Tour'},\n",
              " {'subject': 'general classification',\n",
              "  'relation': 'is with',\n",
              "  'object': '2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'climber Romain Bardet', 'relation': 'sits', 'object': 'second'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas fourth'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in general classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification with 2018 champion Geraint Thomas'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in general classification'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification'},\n",
              " {'subject': 'French climber Romain Bardet',\n",
              "  'relation': 'sits',\n",
              "  'object': 'second in classification'},\n",
              " {'subject': 'climber Romain Bardet',\n",
              "  'relation': 'now sits',\n",
              "  'object': 'second in classification'},\n",
              " {'subject': 'he', 'relation': 'cracked', 'object': 'around 4.5 km remaining'},\n",
              " {'subject': 'km', 'relation': 'concede', 'object': 'almost three minutes'},\n",
              " {'subject': 'his smiles', 'relation': 'turned', 'object': 'he cracked badly'},\n",
              " {'subject': 'Slovenian',\n",
              "  'relation': 'fending off',\n",
              "  'object': 'several attacks on penultimate climb'},\n",
              " {'subject': 'race', 'relation': 'reached However', 'object': 'its point'},\n",
              " {'subject': 'race', 'relation': 'reached', 'object': 'its point'},\n",
              " {'subject': 'he',\n",
              "  'relation': 'cracked badly',\n",
              "  'object': 'around 4.5 km remaining'},\n",
              " {'subject': 'his smiles', 'relation': 'turned', 'object': 'he cracked'},\n",
              " {'subject': 'race',\n",
              "  'relation': 'reached However',\n",
              "  'object': 'its highest point'},\n",
              " {'subject': 'he', 'relation': 'cracked badly', 'object': 'km remaining'},\n",
              " {'subject': 'he', 'relation': 'cracked', 'object': 'km remaining'},\n",
              " {'subject': 'Slovenian',\n",
              "  'relation': 'fending off',\n",
              "  'object': 'several attacks'},\n",
              " {'subject': 'Slovenian',\n",
              "  'relation': 'fending off',\n",
              "  'object': 'attacks on penultimate climb'},\n",
              " {'subject': 'Slovenian', 'relation': 'fending off', 'object': 'attacks'},\n",
              " {'subject': 'race', 'relation': 'reached', 'object': 'its highest point'},\n",
              " {'subject': 'his confident smiles',\n",
              "  'relation': 'turned',\n",
              "  'object': 'he cracked'},\n",
              " {'subject': 'Slovenian', 'relation': 'appeared', 'object': 'untroubled'},\n",
              " {'subject': 'his confident smiles',\n",
              "  'relation': 'turned',\n",
              "  'object': 'he cracked badly'},\n",
              " {'subject': \"Bardet 's break\", 'relation': 'set', 'object': 'wheels'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'also accelerating from',\n",
              "  'object': 'Pogacar'},\n",
              " {'subject': 'motion', 'relation': 'is with', 'object': 'Vingegaard'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'accelerating from',\n",
              "  'object': 'Pogacar'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'set wheels in',\n",
              "  'object': 'motion with Vingegaard'},\n",
              " {'subject': 'Bardet', 'relation': 'has', 'object': 'break'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'accelerating away from',\n",
              "  'object': 'Pogacar'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'also accelerating away from',\n",
              "  'object': 'Pogacar'},\n",
              " {'subject': \"Bardet 's break\",\n",
              "  'relation': 'set wheels in',\n",
              "  'object': 'motion'},\n",
              " {'subject': 'Pogacar', 'relation': 'limiting', 'object': 'his losses'},\n",
              " {'subject': 'Pogacar',\n",
              "  'relation': 'had',\n",
              "  'object': 'little help from team-mates'},\n",
              " {'subject': 'Pogacar',\n",
              "  'relation': 'limiting',\n",
              "  'object': 'his losses on climbs'},\n",
              " {'subject': 'Rafal Majka',\n",
              "  'relation': 'has',\n",
              "  'object': 'seemingly worsening condition'},\n",
              " {'subject': 'Pogacar', 'relation': 'had', 'object': 'help'},\n",
              " {'subject': 'withdrawal', 'relation': 'is with', 'object': 'Covid'},\n",
              " {'subject': 'Pogacar', 'relation': 'had', 'object': 'help from team-mates'},\n",
              " {'subject': 'Pogacar', 'relation': 'had', 'object': 'little help'},\n",
              " {'subject': \"Britain 's Thomas\", 'relation': 'riding', 'object': 'clear'},\n",
              " {'subject': \"Britain 's Thomas\",\n",
              "  'relation': 'capitalised',\n",
              "  'object': 'riding'},\n",
              " {'subject': \"Britain 's Thomas\",\n",
              "  'relation': 'also capitalised',\n",
              "  'object': 'riding'},\n",
              " {'subject': \"Britain 's Thomas\",\n",
              "  'relation': 'riding',\n",
              "  'object': 'clear of 23-year-old'},\n",
              " {'subject': 'Britain', 'relation': 'has', 'object': 'Thomas'},\n",
              " {'subject': 'I', 'relation': 'was', 'object': 'so good'},\n",
              " {'subject': 'I', 'relation': 'was still so good At', 'object': 'Galibier'},\n",
              " {'subject': 'I', 'relation': 'was', 'object': 'still good'},\n",
              " {'subject': 'I', 'relation': 'was', 'object': 'good'},\n",
              " {'subject': 'I', 'relation': 'was', 'object': 'still so good'},\n",
              " {'subject': 'I', 'relation': 'was good At', 'object': 'Galibier'},\n",
              " {'subject': 'I', 'relation': 'was still good At', 'object': 'Galibier'},\n",
              " {'subject': 'I', 'relation': 'was so good At', 'object': 'Galibier'},\n",
              " {'subject': 'I', 'relation': 'got', 'object': 'lot attacking'},\n",
              " {'subject': 'I',\n",
              "  'relation': 'got',\n",
              "  'object': 'lot attacking from Jumbo-Visma'},\n",
              " {'subject': 'It', 'relation': 'is', 'object': 'yet'},\n",
              " {'subject': 'It', 'relation': 'is', 'object': 'over yet'},\n",
              " {'subject': 'it', 'relation': 'has', 'object': 'me'},\n",
              " {'subject': 'He', 'relation': 'got', 'object': 'three minutes'},\n",
              " {'subject': 'We', 'relation': 'will fight until', 'object': 'end'}]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 📝 TODO: Display extracted relations for the first document\n",
        "docs[2].relations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1pKG1UDWc76"
      },
      "source": [
        "### Step 6b: Using LLMs\n",
        "\n",
        "As an alternative to OpenIE, we will use LLMs to do the same task and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "pF0n8sChWieD"
      },
      "outputs": [],
      "source": [
        "def extract_relations_with_llm(text):\n",
        "    # Define the custom prompt for extracting relations\n",
        "    prompt = f\"\"\"\n",
        "    Extract relations from the following text and format them as a JSON array.\n",
        "    Each relation should be an object with \"subject\", \"relation\", and \"object\" fields.\n",
        "    Example: [{{'subject': 'Jonas Vingegaard', 'relation': 'was crowned Tour France champion for', 'object': 'time after 109th edition of race ended'}}, {{'subject': 'Jonas Vingegaard', 'relation': 'was crowned Tour France champion for', 'object': 'first time after edition of race ended on Sunday'}}]\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate the relations using the LLM\n",
        "    llm_output = llm_generate({\"prompt\": prompt})\n",
        "\n",
        "    # Parse the LLM output to extract relations\n",
        "    try:\n",
        "        extracted_relations = json.loads(llm_output[\"response\"])\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle the case where the LLM output is not valid JSON\n",
        "        extracted_relations = []\n",
        "\n",
        "    return extracted_relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "3J4QePdoWoiH"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "  doc.llm_relations = extract_relations_with_llm(doc.raw_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soquKeV6WoiI"
      },
      "source": [
        "Display relations which have been extracted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "7k1TEbohWoiI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'subject': 'Jonas Vingegaard',\n",
              "  'relation': 'launched a stunning attack on the final climb of stage 11 to claim the Tour de France lead from',\n",
              "  'object': 'defending champion Tadej Pogacar'},\n",
              " {'subject': 'Tadej Pogacar',\n",
              "  'relation': 'lost the Tour de France lead to',\n",
              "  'object': 'Jonas Vingegaard on Col du Granon'},\n",
              " {'subject': 'Jonas Vingegaard',\n",
              "  'relation': 'claimed his first Tour stage win atop',\n",
              "  'object': 'Col du Granon'},\n",
              " {'subject': 'Jonas Vingegaard',\n",
              "  'relation': 'now leads the Tour de France by more than two minutes ahead of',\n",
              "  'object': 'Tadej Pogacar'},\n",
              " {'subject': 'Romain Bardet',\n",
              "  'relation': 'now sits second in the general classification behind',\n",
              "  'object': 'Jonas Vingegaard'},\n",
              " {'subject': 'Geraint Thomas',\n",
              "  'relation': 'is fourth in the general classification, just four seconds behind',\n",
              "  'object': 'Tadej Pogacar'},\n",
              " {'subject': 'Tadej Pogacar',\n",
              "  'relation': 'dropped to third place in the general classification behind',\n",
              "  'object': 'Romain Bardet and Geraint Thomas'},\n",
              " {'subject': 'Tadej Pogacar',\n",
              "  'relation': 'cracked badly on the final climb of Col du Granon and conceded almost three minutes to',\n",
              "  'object': 'Jonas Vingegaard'}]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the extracted relations for the first document\n",
        "display(docs[2].llm_relations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_YdNyfHGlC1"
      },
      "source": [
        "## Step 7: Implement some mappings between the entity types and relations returned with a given cycling ontology\n",
        "We will implement mappings between the entity types and relations returned with the cycling ontology available at https://nextcloud.eurecom.fr/s/yKaMDEnRoSqjNAL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "uwo01wgOGmMc"
      },
      "outputs": [],
      "source": [
        "import rdflib\n",
        "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
        "import urllib.parse\n",
        "\n",
        "# Create an RDF graph\n",
        "g = Graph()\n",
        "\n",
        "# Define namespaces\n",
        "CYCLING = Namespace(\"https://purl.org/websem/cycling#\")\n",
        "FOAF = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
        "XSD = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
        "\n",
        "# Bind namespaces\n",
        "g.bind(\"cycling\", CYCLING)\n",
        "g.bind(\"foaf\", FOAF)\n",
        "g.bind(\"xsd\", XSD)\n",
        "\n",
        "# Function to create URI for an entity\n",
        "def create_entity_uri(entity):\n",
        "    return URIRef(f\"https://purl.org/websem/cycling/{urllib.parse.quote(entity['text'].replace(' ', '_'))}\")\n",
        "\n",
        "# Add entities to the graph\n",
        "for doc in docs:\n",
        "    for entity in doc.spacy_entities:\n",
        "        entity_uri = create_entity_uri(entity)\n",
        "        g.add((entity_uri, RDF.type, CYCLING.Person if entity['label'] == 'PERSON' else CYCLING.Organization))\n",
        "        g.add((entity_uri, FOAF.name, Literal(entity['text'], datatype=XSD.string)))\n",
        "\n",
        "    for ent in doc.llm_entities:\n",
        "        entity_uri = create_entity_uri(ent)\n",
        "        g.add((entity_uri, RDF.type, CYCLING.Person if ent['label'] == 'PERSON' else CYCLING.Organization))\n",
        "        g.add((entity_uri, FOAF.name, Literal(ent['text'], datatype=XSD.string)))\n",
        "\n",
        "    for entity in doc.wiki_entities.get('wikidata', []):\n",
        "        entity_uri = create_entity_uri(entity)\n",
        "        if 'label' in entity:\n",
        "            g.add((entity_uri, RDF.type, CYCLING.Person if entity['label'] == 'PERSON' else CYCLING.Organization))\n",
        "            g.add((entity_uri, FOAF.name, Literal(entity['text'], datatype=XSD.string)))\n",
        "            # Load the cycling ontology\n",
        "            g.parse(\"cycling.owl\", format=\"xml\")\n",
        "\n",
        "            # Add Wikidata IDs to the graph\n",
        "            for doc in docs:\n",
        "                for entity in doc.wiki_entities.get('wikidata', []):\n",
        "                    entity_uri = create_entity_uri(entity)\n",
        "                    if 'wikidata_id' in entity:\n",
        "                        g.add((entity_uri, CYCLING.wikidata, Literal(entity['wikidata_id'], datatype=XSD.string)))\n",
        "\n",
        "# Add relations to the graph\n",
        "for doc in docs:\n",
        "    for relation in doc.relations:\n",
        "        if 'subject' in relation and 'relation' in relation and 'object' in relation:\n",
        "            subject_uri = create_entity_uri({'text': relation['subject']})\n",
        "            object_uri = create_entity_uri({'text': relation['object']})\n",
        "            g.add((subject_uri, CYCLING[relation['relation'].replace(' ', '_')], object_uri))\n",
        "\n",
        "    for relation in doc.llm_relations:\n",
        "        if 'subject' in relation and 'relation' in relation and 'object' in relation:\n",
        "            subject_uri = create_entity_uri({'text': relation['subject']})\n",
        "            object_uri = create_entity_uri({'text': relation['object']})\n",
        "            g.add((subject_uri, CYCLING[relation['relation'].replace(' ', '_')], object_uri))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "Nq4jHBEsUxCo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=Nbf93cb36bc204f028e7990e20ca3c044 (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the result into a file\n",
        "g.serialize(destination='output.ttl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJXcKJUZGmqM"
      },
      "source": [
        "## Step 8: Load the data in the Corese engine with the ontology and write the SPARQL queries to retrieve specific information from the KG\n",
        "We will load the data in the [Corese](http://wimmics.inria.fr/doc/tutorial/corese-3.2.3c.jar) engine (the same you used in the Assignment 2) with the ontology and write the SPARQL queries to retrieve specific information from the KG. We will write the following queries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSLn1iZB3BUR"
      },
      "source": [
        "* 📝 List the name of the cycling teams:\n",
        "\n",
        "Team Jumbo, Den/Jumbo-Visma, Alpecin-Deceuninck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ITJ6LO3C9J"
      },
      "source": [
        "* 📝 List the name of the cycling riders\n",
        "\n",
        "Chris Froome, Tom Pidcock, Adam Yates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5u5FyOq3FjB"
      },
      "source": [
        "* 📝 Retrieve the name of the winner of the Prologue\n",
        "\n",
        "Jonas Vingegaard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRpBPPYR3HTi"
      },
      "source": [
        "📝 We will also write the same 3 queries on Wikidata starting from `Q98043180` to compare the results.\n",
        "\n",
        "- List the name of the cycling teams\n",
        "\n",
        "`SELECT DISTINCT ?teamName WHERE {\n",
        "  ?team wdt:P31 wd:Q98043180 .\n",
        "  ?team rdfs:label ?teamName .\n",
        "  FILTER(LANG(?teamName) = \"en\")\n",
        "}`\n",
        "\n",
        "- List the name of the cycling riders\n",
        "\n",
        "`SELECT DISTINCT ?riderName WHERE {\n",
        "  ?rider wdt:P31 wd:Q5 .\n",
        "  ?rider wdt:P106 wd:Q2066131 .\n",
        "  ?rider rdfs:label ?riderName .\n",
        "  FILTER(LANG(?riderName) = \"en\")\n",
        "}`\n",
        "\n",
        "- Retrieve the name of the winner of the Prologue\n",
        "\n",
        "`SELECT DISTINCT ?winnerName WHERE {\n",
        "  ?prologue wdt:P31 wd:Q98043180 .\n",
        "  ?prologue wdt:P1346 ?winner .\n",
        "  ?winner rdfs:label ?winnerName .\n",
        "  FILTER(LANG(?winnerName) = \"en\")\n",
        "}`\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
